---
sidebar_position: 5
description: Archive reports to S3 object storage - AWS S3, MinIO, and S3-compatible storage for compliance and historical records.
keywords: [S3 archiving, AWS S3, MinIO, object storage, report archive, compliance storage]
---

# S3 Object Storage
Archive reports to S3-compatible object storage for long-term retention, compliance, and historical reference.

![](images/s3.png)

## Use Cases

| Scenario | Benefit |
|----------|---------|
| **Compliance archiving** | Immutable records for audit requirements |
| **Historical reference** | "What did this dashboard look like on date X?" |
| **Long-term retention** | Store beyond housekeeping limits |
| **Cross-system access** | Other tools can retrieve archived reports |

## Configuration

| Field | Description | Required |
|-------|-------------|----------|
| **Name** | Interface identifier | Yes |
| **Type** | S3 Object Storage | Yes |
| **Access key ID** | AWS access key or S3-compatible credentials | Yes |
| **Secret access key** | AWS secret key (stored encrypted) | Yes |
| **Region** | AWS region (e.g., `eu-west-1`) | Yes |
| **Bucket name** | Target S3 bucket | Yes |
| **Custom endpoint** | For S3-compatible storage (MinIO, etc.) | No |

## Provider Configurations

### AWS S3

```
Access key ID: AKIAIOSFODNN7EXAMPLE
Secret access key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
Region: eu-west-1
Bucket name: my-reports-bucket
Custom endpoint: (leave empty)
```

### MinIO (Self-Hosted)

```
Access key ID: minioadmin
Secret access key: minioadmin
Region: us-east-1
Bucket name: anaphora-reports
Custom endpoint: https://minio.internal:9000
```

### DigitalOcean Spaces

```
Access key ID: DO00EXAMPLE
Secret access key: your-secret-key
Region: nyc3
Bucket name: my-space-name
Custom endpoint: https://nyc3.digitaloceanspaces.com
```

### Backblaze B2

```
Access key ID: your-key-id
Secret access key: your-application-key
Region: us-west-002
Bucket name: your-bucket
Custom endpoint: https://s3.us-west-002.backblazeb2.com
```

## Path Organization

Reports are stored with a configurable path structure. Configure the path prefix in the job's Delivery settings:

```
s3://my-reports-bucket/
├── anaphora/
│   ├── daily-dashboards/
│   │   ├── 2025/
│   │   │   ├── 01/
│   │   │   │   ├── 2025-01-15-dashboard.pdf
│   │   │   │   └── 2025-01-16-dashboard.pdf
│   ├── compliance-reports/
│   │   └── ...
│   └── alerts/
│       └── ...
```

### Path Variables

Use variables in the path prefix for automatic organization:

| Variable | Description | Example |
|----------|-------------|---------|
| `{{year}}` | 4-digit year | `2025` |
| `{{month}}` | 2-digit month | `01` |
| `{{day}}` | 2-digit day | `15` |
| `{{job_name}}` | Job identifier | `daily-dashboard` |
| `{{date}}` | Full date | `2025-01-15` |

**Example path prefix:** `anaphora/{{job_name}}/{{year}}/{{month}}/`

## IAM Permissions

For AWS S3, the IAM user/role needs these permissions:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::my-reports-bucket",
        "arn:aws:s3:::my-reports-bucket/*"
      ]
    }
  ]
}
```

:::tip Least Privilege
For write-only archiving, you can remove `s3:GetObject` permission.
:::

## Lifecycle Policies

Configure S3 lifecycle policies for automatic management:

| Policy | Description |
|--------|-------------|
| **Transition to Glacier** | Move old reports to cheaper storage |
| **Expiration** | Auto-delete after retention period |
| **Versioning** | Keep multiple versions for compliance |

### Example Lifecycle Rule (AWS)

```json
{
  "Rules": [
    {
      "ID": "ArchiveOldReports",
      "Status": "Enabled",
      "Filter": { "Prefix": "anaphora/" },
      "Transitions": [
        {
          "Days": 90,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 365
      }
    }
  ]
}
```

## Testing

1. Configure the S3 interface with your credentials
2. Click **Test**
3. Verify a test file appears in your bucket
4. Check the file path matches your expectations

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Access Denied | Verify IAM permissions, check bucket policy |
| Invalid credentials | Double-check access key and secret |
| Bucket not found | Verify bucket name and region match |
| Connection timeout | Check custom endpoint URL, verify network access |
| SSL certificate error | For self-signed certs, configure trust settings |

## Best Practices

### Security

- Use dedicated IAM credentials with minimal permissions
- Enable bucket versioning for compliance requirements
- Consider enabling server-side encryption (SSE-S3 or SSE-KMS)
- Restrict bucket access with bucket policies

### Organization

- Use consistent path prefixes across jobs
- Include date components for easy browsing
- Separate compliance reports from operational reports
- Document your bucket structure

### Cost Management

- Configure lifecycle policies to transition old data to Glacier
- Set expiration for non-critical reports
- Monitor bucket size and request costs
- Consider S3 Intelligent-Tiering for variable access patterns
